{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CIFAR-10_Multi-Label_VGG_3-block_BN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgMKYUob9i3T"
      },
      "outputs": [],
      "source": [
        "# import the library\n",
        "import tensorflow as tf  \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
        "from tensorflow.keras.layers import GlobalMaxPooling2D, MaxPooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "import sys\n",
        "from matplotlib import pyplot\n",
        "from keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.keras.optimizers import SGD, Adam\n",
        "from keras import callbacks\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in the data\n",
        "cifar10 = tf.keras.datasets.cifar10\n",
        " \n",
        "# Distribute it to train and test set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDmag6aMKuAg",
        "outputId": "d22d1a00-4888-437f-d2aa-b474be55430e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "170508288/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Multi-label Encoding\n",
        "def  multi_label_encoding(y):\n",
        "  animals = [ 3, 4, 5, 6, 7]\n",
        "  vehicles = [0, 1, 8, 9]\n",
        "  fly = [0,2]\n",
        "  walk = [2, 3, 4, 5, 9]\n",
        "  jump = [3, 4, 5, 6, 7]\n",
        "  swim = [3, 4, 6, 7, 8 ]\n",
        "  new_y = np.zeros((len(y), 6), dtype=np.uint8)\n",
        "  copy_y= y.copy()\n",
        "  for i in range(0, len(y)):\n",
        "    if copy_y[i] in animals:\n",
        "      new_y[i][0] = 1\n",
        "    if copy_y[i] in vehicles:\n",
        "      new_y[i][1] = 1\n",
        "    if copy_y[i] in fly:\n",
        "      new_y[i][2] = 1\n",
        "    if copy_y[i] in walk:\n",
        "      new_y[i][3] = 1\n",
        "    if copy_y[i] in jump:\n",
        "      new_y[i][4] = 1\n",
        "    if copy_y[i] in swim:\n",
        "      new_y[i][5] = 1\n",
        "  return  new_y\n",
        "\n",
        "def scale_pixel(x):\n",
        "  # convert from integers to floats\n",
        "  new_x = x.astype('float32')\n",
        "  # normalize to range 0-1\n",
        "  new_x = new_x / 255.0\n",
        "  return new_x\n",
        "\n",
        "Y_train = multi_label_encoding(y_train)\n",
        "y_test = multi_label_encoding(y_test)\n",
        "X_train = scale_pixel(x_train)\n",
        "x_test = scale_pixel(x_test)\n",
        "x_val, x_train,y_val,y_train= train_test_split(X_train, Y_train, test_size = 0.8)"
      ],
      "metadata": {
        "id": "KtaXWK7KOBSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define cnn model\n",
        "def define_model():\n",
        "\tmodel = Sequential()\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(MaxPooling2D((2, 2)))\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.2))\n",
        "\tmodel.add(Dense(6, activation='sigmoid'))\n",
        "\t# compile model\n",
        "\topt = SGD(learning_rate=0.001, momentum=0.9)\n",
        "\tmodel.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\treturn model\n",
        "\n",
        "def summarize_diagnostics(history):\n",
        "  # plot loss\n",
        "  pyplot.subplot(211)\n",
        "  pyplot.title('Cross Entropy Loss')\n",
        "  pyplot.plot(history.history['loss'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
        "  # plot accuracy\n",
        "  pyplot.subplot(212)\n",
        "  pyplot.title('Classification Accuracy')\n",
        "  pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
        "  pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
        "  # save plot to file\n",
        "  filename = sys.argv[0].split('/')[-1]\n",
        "  pyplot.savefig(filename + '_plot.png')\n",
        "  pyplot.close()"
      ],
      "metadata": {
        "id": "VypfVvzZS1Az"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the test harness for evaluating a model\n",
        "def run_test_harness():\n",
        "  model = define_model()\n",
        "\t# fit model\n",
        "  history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test), verbose=0)\n",
        "\t# evaluate model\n",
        "  _, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "  print('> %.3f' % (acc * 100.0))\n",
        "\t# learning curves\n",
        "  summarize_diagnostics(history)\n",
        "\n",
        "# entry point, run the test harness\n",
        "run_test_harness()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ncMy0epkmT4",
        "outputId": "5238d10c-286d-4fac-f5db-c7886844d4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> 87.870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "BoWPLxd9mMmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "OwnKAejxG4vM"
      }
    }
  ]
}