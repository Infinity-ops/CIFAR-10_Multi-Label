{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Infinity-ops/CIFAR-10_Multi-Label/blob/main/New_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zyu89zWbiOmy"
      },
      "outputs": [],
      "source": [
        "# Keras imports for the convolutional neural network\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
        "from keras.layers import Conv2D, MaxPooling2D, UpSampling2D, Concatenate,  Input\n",
        "from keras import backend as K\n",
        "from keras import losses\n",
        "from tensorflow.keras import optimizers\n",
        "from keras import callbacks\n",
        "from keras.initializers import RandomNormal\n",
        "\n",
        "# Additional packages\n",
        "from PIL import Image\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn import utils \n",
        "from sklearn.model_selection import KFold\n",
        "import IPython.display as dp\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# plt.rcParams['figure.figsize'] = (18, 6)\n",
        "from scipy.stats import itemfreq\n",
        "from math import floor, ceil\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnisWSNAnONG",
        "outputId": "7b789b63-ac12-4d66-d22b-42f3d786a5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28) (60000,)\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(X_train.shape,y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aZHUKnIynXkG"
      },
      "outputs": [],
      "source": [
        "#normalize data\n",
        "if X_train.max() >1:\n",
        "    X_train = X_train / 255\n",
        "    X_test = X_test / 255\n",
        "\n",
        "default_shape = X_train.shape\n",
        "#reshape input data to 1 channel\n",
        "X_train = X_train.reshape(-1,default_shape[1],default_shape[2],1)\n",
        "X_test = X_test.reshape(-1,default_shape[1],default_shape[2],1)\n",
        "image_dim = X_train.shape[1:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lILAumbzQuB7",
        "outputId": "714ae9ca-0a3f-48fd-c1bc-c4301f121cb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYxWX3SOni1i",
        "outputId": "7c3f6c79-d022-4e34-9a6d-121c2d8fe08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 14, 14, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 7, 7, 64)         0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 7, 7, 128)         73856     \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 6272)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               627300    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 719,972\n",
            "Trainable params: 719,972\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "image_dim = X_train.shape[1:]\n",
        "encoder = Sequential()\n",
        "encoder.add(Conv2D(32,kernel_size=(3,3), strides=(1,1),padding='same', activation='relu',input_shape=image_dim))\n",
        "encoder.add(MaxPooling2D(2,2))\n",
        "encoder.add(Conv2D(64,kernel_size=(3,3), strides=(1,1),padding='same',activation='relu'))\n",
        "encoder.add(MaxPooling2D(2,2))\n",
        "encoder.add(Conv2D(128,kernel_size=(3,3), strides=(1,1),padding='same',activation='relu'))\n",
        "encoder.add(Flatten())\n",
        "encoder.add(Dense(100,activation='sigmoid'))\n",
        "encoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4F-gO-jPQXx",
        "outputId": "5ec8af46-c132-4f7e-8e21-770d6a96c5a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 6272)              633472    \n",
            "                                                                 \n",
            " reshape_1 (Reshape)         (None, 7, 7, 128)         0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 7, 7, 128)         147584    \n",
            "                                                                 \n",
            " up_sampling2d_2 (UpSampling  (None, 14, 14, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 64)        73792     \n",
            "                                                                 \n",
            " up_sampling2d_3 (UpSampling  (None, 28, 28, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 28, 28, 1)         577       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 855,425\n",
            "Trainable params: 855,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "encoder_out_dim = encoder.layers[-1].output_shape[1:]\n",
        "decoder = Sequential()\n",
        "decoder.add(Dense(6272, activation='sigmoid', input_shape=encoder_out_dim))\n",
        "decoder.add(Reshape(( 7, 7, 128)))\n",
        "decoder.add(Conv2D(128,kernel_size=(3,3), strides=(1,1),padding='same', activation='relu'))\n",
        "decoder.add(UpSampling2D((2,2)))\n",
        "decoder.add(Conv2D(64,kernel_size=(3,3), strides=(1,1),padding='same', activation='relu'))\n",
        "decoder.add(UpSampling2D((2,2)))\n",
        "decoder.add(Conv2D(1,kernel_size=(3,3), strides=(1,1),padding='same', activation='sigmoid'))\n",
        "decoder.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HtYH8PcoNkix",
        "outputId": "aa8f769e-96e8-4565-9e80-b3394a9d4cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " sequential_3 (Sequential)   (None, 100)               719972    \n",
            "                                                                 \n",
            " sequential_4 (Sequential)   (None, 28, 28, 1)         855425    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,575,397\n",
            "Trainable params: 1,575,397\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "enc_dec = Sequential([encoder,decoder])\n",
        "enc_dec.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ABhKxq9NqCU",
        "outputId": "82f0af0c-946e-4b60-b518-d78e1fe39ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "480/480 - 17s - loss: 0.2685 - val_loss: 0.2622 - 17s/epoch - 36ms/step\n",
            "Epoch 2/1000\n",
            "480/480 - 15s - loss: 0.2634 - val_loss: 0.2628 - 15s/epoch - 31ms/step\n",
            "Epoch 3/1000\n",
            "480/480 - 15s - loss: 0.2634 - val_loss: 0.2624 - 15s/epoch - 31ms/step\n",
            "Epoch 4/1000\n",
            "480/480 - 15s - loss: 0.2634 - val_loss: 0.2622 - 15s/epoch - 32ms/step\n",
            "Epoch 5/1000\n",
            "480/480 - 15s - loss: 0.2634 - val_loss: 0.2623 - 15s/epoch - 32ms/step\n",
            "Epoch 6/1000\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "Restoring model weights from the end of the best epoch: 1.\n",
            "480/480 - 15s - loss: 0.2633 - val_loss: 0.2627 - 15s/epoch - 32ms/step\n",
            "Epoch 6: early stopping\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ],
      "source": [
        "enc_dec.compile(optimizer='nadam', loss = 'binary_crossentropy')\n",
        "es = callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=2, patience=10, restore_best_weights=True)\n",
        "history = enc_dec.fit(X_train,X_train, batch_size=100,epochs=1000,validation_split=0.2, verbose=2,callbacks=[es,es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MrxJhCf-Nh26",
        "outputId": "c2e26b66-b685-4408-932f-c1501bb2ad47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 2s 64ms/step - loss: 0.2626\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.26264050602912903"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "enc_dec.evaluate(X_test,X_test,batch_size=1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLwUP7t6L7GW",
        "outputId": "bb1ca775-e7b6-42fa-c63c-07fe6aba5e07"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "random_label = np.random.randint(0,9999)\n",
        "img_sample = X_test[random_label,:,:].reshape((1,28,28,1))\n",
        "plt.subplot(1,2,1)\n",
        "plt.imshow(img_sample.reshape(28,28), cmap='gray');\n",
        "plt.title('Original image');\n",
        "pred_img = enc_dec.predict(img_sample) \n",
        "plt.subplot(1,2,2)\n",
        "plt.imshow(pred_img.reshape(28,28), cmap='gray');\n",
        "plt.title('Reconstructed image');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9GYe8hiTj4C",
        "outputId": "1fa201b0-581d-4101-8757-5477f2c82229"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 784)\n",
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_21 (InputLayer)       [(None, 1)]               0         \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 128)               256       \n",
            "                                                                 \n",
            " dense_72 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_73 (Dense)            (None, 784)               201488    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 234,768\n",
            "Trainable params: 234,768\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "235/235 [==============================] - 4s 11ms/step - loss: 0.3022 - val_loss: 0.2552\n",
            "Epoch 2/100\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2494 - val_loss: 0.2444\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2433 - val_loss: 0.2406\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2404 - val_loss: 0.2379\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2377 - val_loss: 0.2351\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2352 - val_loss: 0.2332\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2334 - val_loss: 0.2316\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2323 - val_loss: 0.2306\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2316 - val_loss: 0.2300\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2312 - val_loss: 0.2296\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2308 - val_loss: 0.2292\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2304 - val_loss: 0.2288\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2299 - val_loss: 0.2281\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2295 - val_loss: 0.2278\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2291 - val_loss: 0.2274\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2287 - val_loss: 0.2271\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2282 - val_loss: 0.2266\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2279 - val_loss: 0.2263\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2274 - val_loss: 0.2258\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2269 - val_loss: 0.2253\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2263 - val_loss: 0.2246\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2256 - val_loss: 0.2240\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2250 - val_loss: 0.2232\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2244 - val_loss: 0.2230\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2237 - val_loss: 0.2217\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2231 - val_loss: 0.2216\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 2s 7ms/step - loss: 0.2225 - val_loss: 0.2208\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2222 - val_loss: 0.2203\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2219 - val_loss: 0.2201\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2218 - val_loss: 0.2200\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2216 - val_loss: 0.2196\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2215 - val_loss: 0.2197\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2214 - val_loss: 0.2196\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2214 - val_loss: 0.2199\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2213 - val_loss: 0.2196\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2213 - val_loss: 0.2194\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2213 - val_loss: 0.2197\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2212 - val_loss: 0.2194\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2212 - val_loss: 0.2195\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2212 - val_loss: 0.2201\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2212 - val_loss: 0.2197\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2211 - val_loss: 0.2195\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2194\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2212 - val_loss: 0.2195\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2197\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2211 - val_loss: 0.2194\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2196\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2194\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2192\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2211 - val_loss: 0.2193\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2194\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2192\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2196\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2192\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2195\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2194\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2192\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2194\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2210 - val_loss: 0.2195\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2195\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2210 - val_loss: 0.2193\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 2s 8ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2195\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2195\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2208 - val_loss: 0.2192\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2194\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2191\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 1s 6ms/step - loss: 0.2209 - val_loss: 0.2192\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2209 - val_loss: 0.2193\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 0.2208 - val_loss: 0.2192\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3dda6b1b90>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# autoencoder for decoder structure\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "from keras import optimizers\n",
        "from keras.datasets import mnist\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "\n",
        "encoding_dim = Input(shape=(1,))\n",
        "input_img = Input(shape=(784,))\n",
        "\n",
        "decoded_1 = Dense(128, activation='relu')(encoding_dim)\n",
        "decoded_2 = Dense(256, activation='relu')(decoded_1)\n",
        "decoded = Dense(784, activation='sigmoid')(decoded_2)\n",
        "print(decoded.shape)\n",
        "autoencoder = Model(encoding_dim, decoded)\n",
        "\n",
        "myoptimizer = optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-5, amsgrad=False)\n",
        "autoencoder.compile(optimizer=myoptimizer, loss='binary_crossentropy')\n",
        "autoencoder.summary()\n",
        "(x_tr, y_tr), (x_te, y_te) = mnist.load_data()\n",
        "x_tr = x_tr.astype('float32') / 255.\n",
        "x_te = x_te.astype('float32') / 255.\n",
        "x_tr = x_tr.reshape((len(x_tr), np.prod(x_tr.shape[1:])))\n",
        "x_te = x_te.reshape((len(x_te), np.prod(x_te.shape[1:])))\n",
        "\n",
        "autoencoder.fit(y_tr, x_tr,\n",
        "                epochs=100,\n",
        "                batch_size=256,\n",
        "                shuffle=True,\n",
        "                validation_data=(y_te, x_te))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rP2pnrl9gGZb",
        "outputId": "ea36ffb2-89f4-4a9f-da13-73f6a909b7e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        }
      ],
      "source": [
        "encoder.save('encoder')\n",
        "autoencoder.save('autoencoder')\n",
        "\n",
        "# duplicate encoders and freeze weights\n",
        "encoder1 = keras.models.load_model('encoder') \n",
        "encoder1._name = 'encoder1'\n",
        "encoder1.trainable = False\n",
        "\n",
        "encoder2 = keras.models.load_model('encoder')\n",
        "encoder2._name = 'encoder2'\n",
        "encoder2.trainable = False\n",
        "\n",
        "autoencoder = keras.models.load_model('autoencoder')\n",
        "autoencoder._name = 'autoencoder'\n",
        "autoencoder.trainable = False\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwHl0uJxgIpy",
        "outputId": "726af0a5-8d79-4a06-c44d-26e03e0fd7e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 10)\n",
            "(28, 28, 1)\n",
            "Model: \"model_33\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_97 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " input_98 (InputLayer)          [(None, 28, 28, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " encoder1 (Sequential)          (None, 100)          719972      ['input_97[0][0]']               \n",
            "                                                                                                  \n",
            " encoder2 (Sequential)          (None, 100)          719972      ['input_98[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_45 (Concatenate)   (None, 200)          0           ['encoder1[45][0]',              \n",
            "                                                                  'encoder2[45][0]']              \n",
            "                                                                                                  \n",
            " dense_290 (Dense)              (None, 1000)         201000      ['concatenate_45[0][0]']         \n",
            "                                                                                                  \n",
            " dense_291 (Dense)              (None, 200)          200200      ['dense_290[0][0]']              \n",
            "                                                                                                  \n",
            " units_add (Dense)              (None, 10)           2010        ['dense_291[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 10)          0           ['units_add[0][0]']              \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " dense_292 (Dense)              (None, 200)          200200      ['dense_290[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.argmax_43 (TFOpLambda)  (None,)             0           ['tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tens_add (Dense)               (None, 1)            201         ['dense_292[0][0]']              \n",
            "                                                                                                  \n",
            " model_10 (Functional)          (None, 784)          234768      ['tens_add[0][0]',               \n",
            "                                                                  'tf.math.argmax_43[0][0]']      \n",
            "                                                                                                  \n",
            " tf.reshape_64 (TFOpLambda)     (28, 28, 1)          0           ['model_10[46][0]']              \n",
            "                                                                                                  \n",
            " tf.reshape_63 (TFOpLambda)     (28, 28, 1)          0           ['model_10[45][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,278,323\n",
            "Trainable params: 838,379\n",
            "Non-trainable params: 1,439,944\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "# create model to learn it all\n",
        "input1 = Input(shape=image_dim)\n",
        "input2 = Input(shape=image_dim)\n",
        "enc1_out = encoder1(input1)\n",
        "enc2_out = encoder2(input2)\n",
        "model_c = Concatenate()([enc1_out,enc2_out])\n",
        "model_c = Dense(1000,activation='relu')(model_c)\n",
        "model_b1 = Dense(200,activation='relu')(model_c)\n",
        "model_b2 = Dense(200,activation='relu')(model_c)\n",
        "model_b3 = Dense(200,activation='relu')(model_c)\n",
        "model_b4 = Dense(200,activation='relu')(model_c)\n",
        "model_b5 = Dense(200,activation='relu')(model_c)\n",
        "\n",
        "units_add =  Dense(10,activation='softmax',name ='units_add')(model_b1)\n",
        "print((units_add.shape))\n",
        "\n",
        "tens_add = Dense(1,activation='sigmoid',name ='tens_add')(model_b2)\n",
        "\n",
        "dec2_out = autoencoder(tens_add)\n",
        "dec2_out = tensorflow.reshape(dec2_out, [28,28,1])\n",
        "dec1_out = autoencoder(K.argmax(units_add[0:], axis=-1))\n",
        "dec1_out = tensorflow.reshape(dec1_out,[28,28,1])\n",
        "print(dec1_out.shape)\n",
        "model_complete = Model(inputs=[input1,input2],outputs=[dec1_out, dec2_out])\n",
        "model_complete.compile(optimizer='nadam', loss = ['binary_crossentropy','binary_crossentropy'], metrics=['acc'])\n",
        "model_complete.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3fONYlEkNy4"
      },
      "outputs": [],
      "source": [
        "(X_train_keras, y_train_keras), (X_test_keras, y_test_keras) = mnist.load_data()\n",
        "\n",
        "#Dataset for additions\n",
        "# Generate the 100 unique pairs\n",
        "unique_pairs = [str(x)+str(y) for x in range(10) for y in range(10)]\n",
        "#print(unique_pairs)\n",
        "# Create 10 test set pairs\n",
        "test_set_pairs = []\n",
        "\n",
        "while(len(test_set_pairs) < 10):\n",
        "    pair_to_add = random.choice(unique_pairs)\n",
        "    if pair_to_add not in test_set_pairs:\n",
        "        test_set_pairs.append(pair_to_add)\n",
        "\n",
        "#Use the remaining 90 as training set pairs\n",
        "train_set_pairs = list(set(unique_pairs) - set(test_set_pairs))\n",
        "\n",
        "\n",
        "# Ensure there are 90 training set pairs and 10 test set pairs\n",
        "assert(len(test_set_pairs) == 10)\n",
        "assert(len(train_set_pairs) == 90)\n",
        "\n",
        "# Ensure no test set pairs appear in the training set pairs:\n",
        "for test_set in test_set_pairs:\n",
        "    assert(test_set not in train_set_pairs)\n",
        "    #print(\"%s not in training set.\" % test_set)\n",
        "    \n",
        "from keras import backend as K\n",
        "import math\n",
        "y = 30\n",
        "\n",
        "def num2img(num):\n",
        "    first_digit = floor(num/10)\n",
        "    last_digit = num%10\n",
        "    y = np.zeros((28,56), dtype=\"uint8\")\n",
        "    first = find_n_array(first_digit)\n",
        "    sec = find_n_array(last_digit)\n",
        "    # Populate the empty matrix with data from two image matrices from the training set\n",
        "    y[:,:28] = X_train_keras[first]\n",
        "    y[:,28:] = X_train_keras[sec]\n",
        "    return y\n",
        "\n",
        "\n",
        "def find_n_array(num):\n",
        "    for i in range(0, len(y_train_keras)):\n",
        "        if num == y_train_keras[i]:\n",
        "            index = i\n",
        "            break\n",
        "    return index \n",
        "\n",
        "#Image.fromarray(num2img(18))\n",
        "X_train_1 = []\n",
        "X_train_2 = []\n",
        "y_train_1 = []\n",
        "y_train_2 = []\n",
        "\n",
        "# Number of samples per permutation (e.g. there are 90 permutations in the train set so 1000 * 90)\n",
        "samples_per_permutation = 10  # Set to 10 for brevity. Results in the paper were for 1,000 samples.\n",
        "\n",
        "for train_set_pair in train_set_pairs:\n",
        "    for _ in range(samples_per_permutation):\n",
        "        rand_i = np.random.choice(np.where(y_train_keras == int(train_set_pair[0]))[0])\n",
        "        rand_j = np.random.choice(np.where(y_train_keras == int(train_set_pair[1]))[0])\n",
        "        X_train_1.append(X_train_keras[rand_i])\n",
        "        X_train_2.append(X_train_keras[rand_j])\n",
        "        y_train_1.append((num2img(y_train_keras[rand_i] + y_train_keras[rand_j]))[:,:28])\n",
        "        y_train_2.append((num2img(y_train_keras[rand_i] + y_train_keras[rand_j]))[:,28:])        \n",
        "\n",
        "        \n",
        "X_test_1 = []\n",
        "X_test_2 = []\n",
        "y_test_1 = []\n",
        "y_test_2 = []\n",
        "\n",
        "for test_set_pair in test_set_pairs:\n",
        "    for _ in range(samples_per_permutation):\n",
        "        rand_i = np.random.choice(np.where(y_test_keras == int(test_set_pair[0]))[0])\n",
        "        rand_j = np.random.choice(np.where(y_test_keras == int(test_set_pair[1]))[0])\n",
        "        X_test_1.append(X_test_keras[rand_i])\n",
        "        X_test_2.append(X_test_keras[rand_j])\n",
        "        y_test_1.append((num2img(y_test_keras[rand_i] + y_test_keras[rand_j]))[:,:28])\n",
        "        y_test_2.append((num2img(y_test_keras[rand_i] + y_test_keras[rand_j]))[:,28:])\n",
        "        \n",
        "#print(\"Training set size: %s, test set size: %s\" % (len(X_train), len(X_test)))\n",
        "\n",
        "# The training set should be 90,000 images in size (90 permutations * 1000)\n",
        "# and the label data, y_train, must also be equal in length.\n",
        "assert(len(X_train_1) == samples_per_permutation * 90)\n",
        "assert(len(X_train_1) == len(y_train_1))\n",
        "assert(len(X_train_2) == samples_per_permutation * 90)\n",
        "assert(len(X_train_2) == len(y_train_2))\n",
        "\n",
        "# The test set should be 10,000 images in size (10 permutations * 1000)\n",
        "# and the label data, y_test, must also be equal in length\n",
        "assert(len(X_test_1) == samples_per_permutation * 10)\n",
        "assert(len(X_test_1) == len(y_test_1))\n",
        "assert(len(X_test_2) == samples_per_permutation * 10)\n",
        "assert(len(X_test_2) == len(y_test_2))\n",
        "\n",
        "# Ensure we are using NumPy arrays\n",
        "X_train_1 = np.asarray(X_train_1)\n",
        "y_train_1 = np.asarray(y_train_1)\n",
        "X_test_1 = np.asarray(X_test_1)\n",
        "y_test_1 = np.asarray(y_test_1)\n",
        "\n",
        "X_train_2 = np.asarray(X_train_2)\n",
        "y_train_2 = np.asarray(y_train_2)\n",
        "X_test_2 = np.asarray(X_test_2)\n",
        "y_test_2 = np.asarray(y_test_2)\n",
        "\n",
        "# Reshape the data sets to a format suitable for Keras\n",
        "X_train_1 = X_train_1.reshape(X_train_1.shape[0], X_train_1.shape[1], X_train_1.shape[2], 1)\n",
        "X_test_1 = X_test_1.reshape(X_test_1.shape[0], X_test_1.shape[1], X_test_1.shape[2], 1)\n",
        "y_train_1 = y_train_1.reshape(y_train_1.shape[0], y_train_1.shape[1], y_train_1.shape[2], 1)\n",
        "y_test_1 = y_test_1.reshape(y_test_1.shape[0], y_test_1.shape[1], y_test_1.shape[2], 1)\n",
        "\n",
        "X_train_2 = X_train_2.reshape(X_train_2.shape[0], X_train_2.shape[1], X_train_2.shape[2], 1)\n",
        "X_test_2 = X_test_2.reshape(X_test_2.shape[0], X_test_2.shape[1], X_test_2.shape[2], 1)\n",
        "y_train_2 = y_train_2.reshape(y_train_2.shape[0], y_train_2.shape[1], y_train_2.shape[2], 1)\n",
        "y_test_2 = y_test_2.reshape(y_test_2.shape[0], y_test_2.shape[1], y_test_2.shape[2], 1)\n",
        "\n",
        "# Reformat the images to use floating point values rather than integers between 0-255\n",
        "X_train_1 = X_train_1.astype('float32')\n",
        "X_test_1 = X_test_1.astype('float32')\n",
        "X_train_1 /= 255\n",
        "X_test_1 /= 255\n",
        "X_train_2 = X_train_2.astype('float32')\n",
        "X_test_2 = X_test_2.astype('float32')\n",
        "X_train_2 /= 255\n",
        "X_test_2 /= 255\n",
        "\n",
        "y_train_1 = y_train_1.astype('float32')\n",
        "y_test_1 = y_test_1.astype('float32')\n",
        "y_train_1 /= 255\n",
        "y_test_1 /= 255\n",
        "y_train_2 = y_train_2.astype('float32')\n",
        "y_test_2 = y_test_2.astype('float32')\n",
        "y_train_2 /= 255\n",
        "y_test_2 /= 255\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "units_add[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XXBxcAnKuhu",
        "outputId": "64311903-05a2-40bb-9d03-e3945e287ac0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<KerasTensor: shape=(10,) dtype=float32 (created by layer 'tf.__operators__.getitem_3')>"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R-aJLWEHw7BI",
        "outputId": "15a0ed6f-2132-4a83-db58-b99d19c9cf85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_291/kernel:0', 'dense_291/bias:0', 'units_add/kernel:0', 'units_add/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['dense_291/kernel:0', 'dense_291/bias:0', 'units_add/kernel:0', 'units_add/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-6bef972acfa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_complete\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train_1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 55\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/binary_crossentropy/mul/Mul' defined at (most recent call last):\n    File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n      \"__main__\", mod_spec)\n    File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.7/dist-packages/traitlets/config/application.py\", line 846, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelapp.py\", line 499, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 132, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 541, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.7/asyncio/base_events.py\", line 1786, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.7/asyncio/events.py\", line 88, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/platform/asyncio.py\", line 122, in _handle_events\n      handler_func(fileobj, events)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 452, in _handle_events\n      self._handle_recv()\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 481, in _handle_recv\n      self._run_callback(callback, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/zmq/eventloop/zmqstream.py\", line 431, in _run_callback\n      callback(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/tornado/stack_context.py\", line 300, in null_wrapper\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n      return self.dispatch_shell(stream, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n      handler(stream, idents, msg)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n      user_expressions, allow_stdin)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.7/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2718, in run_cell\n      interactivity=interactivity, compiler=compiler, result=result)\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2822, in run_ast_nodes\n      if self.run_code(code, result):\n    File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-129-6bef972acfa2>\", line 1, in <module>\n      history = model_complete.fit([X_train_1,X_train_2],[y_train_1, y_train_2], batch_size=100,epochs=1000,validation_split=0.2, verbose=1,callbacks=[es,es])\n    File \"/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\", line 64, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1384, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1021, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1010, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 1000, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\", line 863, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 531, in minimize\n      loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 583, in _compute_gradients\n      grads_and_vars = self._get_gradients(tape, loss, var_list, grad_loss)\n    File \"/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\", line 464, in _get_gradients\n      grads = tape.gradient(loss, var_list, grad_loss)\nNode: 'gradient_tape/binary_crossentropy/mul/Mul'\nrequired broadcastable shapes\n\t [[{{node gradient_tape/binary_crossentropy/mul/Mul}}]] [Op:__inference_train_function_419589]"
          ]
        }
      ],
      "source": [
        "history = model_complete.fit([X_train_1,X_train_2],[y_train_1, y_train_2], batch_size=100,epochs=1000,validation_split=0.2, verbose=1,callbacks=[es,es])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T-LT5VKYrNcL",
        "outputId": "b79a3492-133d-4d38-d188-1e7340458aaa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "27\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA50lEQVR4nNXOv0sCYRzH8U9liA231dIhNgiRrS2X0F/QZOBQo0NDBg32DzQJgg22Nbe3CdIaQVuLCDYcIRw0CV6Z3b1pqbB7fAbHPtvzfT3fH9J/ysLfZ3FJ2m5VW+bHdO05AqBrWu6e7/xg6tfynezn4024VpcayT63z8expDK8rybRg4qk5QcmB8ZGDzKSDuHCPMeDHenojaeMiZtD7pz1EYMt06QTKHV42Z9lcnpAuDfTJHcMpxaTrsEv2NAH2ikLhuMALqcKi9MaNWNtWJCVOLQedAVwa8F8ANG5rXXXfz2zzp0rX57LZCBBKLtYAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nGNgoAlgRGJzuNqYn2SYc/cfNoWb//379+/fv3xGbJKP/kFlsRn76HsGA4NKH/dXXiw6Y0IZGBgYyv79CYcKsCBJLmFgYGBgkGZgEsHp/mv/fprjkGKzffvvOS59Af/+/TPEIWf14t//9UxYpZgiX/77N1ERu76Ef//+T2THLjft379/J9iwSnGe+/fv73INrHIKT/79+zcFhzub8chJvfj3byMzmiAsbP//YWAw7z0C5d1U3/cOWZXbPyTw7kkEAwNSfLKk1YsyMDA8XcJwZh8Dw5/POKwfWAAAnF9g1WOmYK0AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmklEQVR4nGNgGPxA69X/2RAWE4acfovwr+849LGd/vs3GpehgX//flXEIaf+7O/nMBxynNP//l2Dy9Cuv38/BOOQ4zr0928cDjn5Q3//nhXAIanz9+87fxxy3Av//p2HyzVtf/++NcDlmv1//ybh0qjw9+8bQ1wa1+KxUfLv3+tcqEIoUXb8Gx7JHbhMZZD8e4sFj2Q8TjnqAgDeRDnwq+OrWQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nGNgoDGIav/3r5IXu5z7z79///6VRhFjgjH0WfCYevXv379/V7Jj18nAwMDA8OwnVkk2VFWoktFqeKxM/Pv379+/nNh1QkAFdsmNDxgYGBj4GBgYGJhcNW34GRgYGBhgvnt3T4GBgUHUUDWFgdHpqdCm5uvIRvj8RQFXUOz89w/K+PMXi3sPQLQ80/PD1AkFTzzvZWDRKbXt79+/f7/cefD379+/L13RZNcgnPPSDcUrDAwML2GMN5unn2VgYGBgYERIKlzlYHj3l2H5xYvnsdjq+/cgDxbhQQQAInxlmsIX3RIAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAArUlEQVR4nGNgGEqAEYktbKxlyCjgw8D4f8u5zWcZGBhYEHKCOw0ZGBivXGC4f0/J79tZVENW/Pv7u0GPhQErKIv7ughVhAnB7FLifIFTkkHx/znckhgAVdIQt+RzRkbckht/C+Cx49kHBdx27uVNxy15ntEYt7Gsl/8K4tT5eyNDCC5JKa0PDMG4JPOuuDGKsOOwkv3G37//NHDo/OnYxsDgjdO57OmHNXBKkgIA++IraGMizSwAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8ElEQVR4nGNgGARA9tb/clxyMlf/PlDFISd9+e8fW1xm3vw71x+HnP2Vv9NYcNl37+8JNgZWhAAjgsl+SYXh8F0GzesM2089QtfY/BcOnoWj6QxaycTwo2f1Sw8VBun42/q/USx89vfZ37vqEM7lv94ohjb+/SpvJgPlXH4igCzHfOZvM5xd87sCRaP83xOcMLbp36caKJKz/zbBmGqP/9qjyHE+/GkFNTPl8e/VTCiSPn8vQRgSa/8+qWZgwCbJXv/o71N9NDkGpnt/WxVTNv38+3e5BrocA8MiSLhdSGLFlGNgTNvyc6KdKh8WKfoCABCMZAvp2tFCAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4UlEQVR4nN2OMUtCURxHzxMhUC84RYJDS0EQiE0NbwkaRKGhxc/R2vQG9/AD5OJS0ncwaKt4Q0vwmp+CoBCu9/9ui/eJ3Xe/gGe6/A733Av7ydk0ldewUN0+i9ZaFnf5EmzdqPaVQKW7Ol/8v6di/a6A+reOnOinxAqAiXzYrWQPbfOwBsCYmSPh5xQgvCKxS3kr+8eDxglRlUfnTSMimYhk8pRveTY1FlzZmQLLl3snCcBB86Z5CKKviz2gMrl0sxsuzGzulyxX/qwMC367YRy8+eWR6flljMFL77fllzv8AeBOTeMqO/ilAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAsElEQVR4nMWPvQ4BYRBFbz5CQanwl1BsoyIeQa/b2muoJPseVCqJRrNRi9BIPINYUSgU6OROVCT7yW2Z7s7JuZkB/j+ZyCxQcEhy8A7Og13gsRJi5UjOPskzizUgEWJ+QrKjWpmCXu0WOF2F2ScZCZbbkIemEs1MPYkdyVhBI/d1waZGhkq8GZOyYOHTOEptHIDSAgBQdUDhS8k2AABjGi8tUXum3XuCtZdrm6tbfzcviCVESO+JkU8AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "91\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABFklEQVR4nMXPsUsCcRQH8K9y0RA1HBQdDSW2OdXa4CL4Dzg0BQUt0SK4NUQ0BdVeRFBIqzTeRUOTguISREREFrRcJBEV5vfdayjJvPut9ab3e5/3g+8D/r9GUqVA9qai8ZAU8nwignL1Nv3Vg/bdaNi2hDwawuRzBC68CbkIZFvl/l4bvJKguZ8Epl8v7VBQspYBgCJPvybWDz46s5UqAOsFtv0UfQxSfE8bCCjx5LuLh8xOxprGj/NymzNZpiUFk800uDvceVgAkN10b2LXLgDMjaHod2879yISiIioiMj6QAfiAKC6tuOqqgaqqsvj3ehvIP9R9QD4lYTjrFz8SpHeJoVkuSedBQBn9T4sHT94numGP6xPL8tzcheNUO8AAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVR4nGNgGKpg52VeBgYGhudfjKACLAg5OW12VgYGBob/rJIY+thn/1nAwMDAwPBsEqahEn8eGzEwMDD4/CiBCTHBJecyzD/HwMDAIIiwCS5Z73VvHgMDAwODHSNcEsYSvMlq9EaJgYHh3iFdvWtoNsb++b7j9J8/f/+c+vAHLoiwgM2FYcsHRgFvhoUYktd6D51mePeHgTVw2RtMn8CAw09F3JK81zsxvQIDlqoMuCXxAbGzf0JxSur//SqK29j/q1/jlJRneIDbzoV/dBEcdJ1ncOsjBQAA9J84Tp+3h8sAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA8ElEQVR4nGNgGGSAEYXnxqBlKOVscAnKZYFLHFNgYJD4z8DA+O0Hhk6lO/8ZGH69v3pu6Y9bmBbs+nvK1QhVCGHsC8blu3E67cpfPXQhJjhLi0GRIfj48RJBbDr/vXGv//f379/XIZhysf/+/fv3pi22/t+/RgxJzn9//+4UZGBgMPj42x5DdvGzQl4GBgYGhtyfu3C6moHh/F8XdNciwH1GSdySiv8xXQRjRH69hO5Xl/lQhtT7L67oGnf+z4bI/fs3CcPU5f9+7snUT5z8/t9GFgxJwcxHf//++/v3y2peLG5k4M1f8G/FDB1sUtQFAEPMVJy/FWF1AAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAqYvQGVz4LM+fwMt8aYKWgCTHAWq3gvE05J46fCZ3FKMjD82IzLQtE3fyJwukb8zx9RdDG4sYoM+z+iS8L96cPw8heDki/DBda35zGM/fzXlani79//f/9+uX7dG03y6p9Hm//8+fP3z58/f/40o9m5nkHKk+GAwdy5xQsxXdvy58/vxSoMDAwMCn/+VGFKfhFjYGBgEDv356UgmqTavT9/Ztgx8Bid/PPHD8Ncu19//nx7/vrzn983ZTFt9XsPce1lTCkGBoZjf/78+ftnjwpWSdG+B3MaFNmwyg0BAAA63V8MtoRlWQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "41\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABAUlEQVR4nGNgoCJgrl/7738BdrmAU//+/fu3Bqtc3M9/J5xdUxWxSHF33FmZyIzDvvX/NgvikGKf9atXHFM43piBgUF0yr/pTLj0tXxdLoFDjiH833JcUgx+X+/b4JKTuvZPF12MBcaIVph0jYGB347h2l0MjcZ/DjJI1Zx7/+/f58M+LKhyTG3/lmc9/ffry59///49EkKVtPz379+/f9OsGdzCpv37NwlVcsO/f68nSbMwMDAw6Pz7twTVQewM/wKOQizwZWC4hCp5n+HtPQYGNjsG1lKHxzdno0qyfhc9e1uWTYqB4WvgofcwyxihtF6EueNt1T2Pf0++iuHNIQIAw5pdvrXDlUoAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6klEQVR4nGNgGATA7b82bkmRfwvhbCYkcS4mBgaGbwy62CSl3iWjmYIkOYntDwMDgyBWSU4Nhp8MDAy+WCW1tG5sZGBgYGC4i0VyJsP2rwwMDKIMypiSxtoMFxgYGFj9Gb4xYIDL//YxMzAwqP37V4guFX3/3///fcoMDGr//pvBRRkZGBgYGJSusd35xyP16fxRoQwGkXeoGjkbp3EzCFt07Pz699+/YmlfHMHb/u/fv3//uiAcFjTJ7wyfUmQZ9mKX5GU4tAa7mQwMDI/+FeCUc/j7bz2Cx4Qqycz4/z1OnVoXLuKUow8AACCnP1KZiOntAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAaElEQVR4nM2QUQ6AIAxDqyfzZoyTISebHyamLYHEH2O/tj26AsAPdGQ89a4oslFnUGWwSLcpTBm9WbuCbXLqjsykZ6ozAOBcZa4gsRF2quUT0gbu5K0D7DMYns+wOOR8v484K1Dd/LkuCVwT3H3lQIgAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA1UlEQVR4nGNgoAlgROGxTGb4n4VLad2/f7m45JTf/PsXh0vS/t+/rUw45ITP/Ptpjktj5b9/a3DJMaz894sHl5zQi38PcGos//c3Bafkxn8H0EQQLhe1Y7iOUzKbn+Fg4KSnv65NssY0tenfv2tf//379+/fGxGoEAuyvAbDw+v8lgxCbNh0vm5iYNC69O+fFIak6v9/92UZGJJ+/FvPjCEp8urfv9u5Lr//nZXAdBDDqr///v379++aOBY5BoZ5//79+/c1DKscg5jHjH/XgrHLDQ4AAKr1VJ5NvBCsAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "17\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nGNgGK5AtHbxq39P1LBJBW38+Pfv37//ejClzNZ8/fvv7/cbn/7ZY8i1//z7dWW5mR7HlX8N6HJO//6et2VgYGAo+fvvGJqc+7//EJvs//37b4QmefzvP20GBgaB+i9//x7ggAqyIOT3fmRg4JZkYGDw/YGmc9bff3///v377+/fv+vhgoxQmq1J2lid4f5zYfXPqq8xvcnAwMDAoP/9H5IUE6qkHtsrSxz6GPgu/L2BxEXVGaLHsAmXRvbz/16K45L0hQUTFLAgcxT+MzxA5qPY6YvLSAYGBtmPf3+44JLk3nYnBI9eNAAAwQhYcTnVVYUAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA4ElEQVR4nGNgoAsQXvb/JBcOucI3//5tMMcqxXri7fp4dlYmrJIhzzdy47KPa/kv3I7Z/C8Zp5znn+XMqCJIlpsyrfqLS6Pt+xMcaEIscJY2/8EfPC72D27u+oehUfDlvwS9O/9e/f23XxZDkuPTv9ZXjxp15374t4AZXdLm37931awMDAxBv/+pokua/f3nBWEdwuLdU//EIIxV/7ZChRD+nMHgCWOqYEheZ+jQgTI/YxjLtPXfp0UyLBy5n/6YYUgyKG799+/fjb//9jrDRBiR9cY7CdovObTnNabGQQIA2jNPfEuVvGcAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "23\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAfklEQVR4nMWSQQ7AIAgEt40Poz/Dl6kvswdaRSAe2z2Y6OwCIQLf61ivRAAADpxUuiiA3IeKg93CczLtbrahREgKmKTMmdFnmWTyRVtPxKobmK+orCA2D7xZwGBMjpXBfBO1OBdUG392Ewd9VDM9awKA+rprWz6BfBNW58+6AVEihWNd33gWAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA+0lEQVR4nMXRrUtDcRTG8SeIRcW3YHEiQyzCgmmCSZxRDCbLQBCDQVCDVRCrmP0DbAMnhhWDMlZckosKK47bdHDvykXhe2YQ0bv9flVP/XBeHo7031Wx+riH+ssGR0Ecn/Xa4jYGAM0ey9+AQXjrwLkWYJzOLP9g3zcOjEjhZqf6Pi2F3Z2jW7W1WUn5O14yvjRFqPnSnLR4zHqwDCx5rGL2NOmmldgI3McMX7WxYMppuQawOyFJQ8XjtI1dAkiS5i+4dxgZKbfxRrKe3vf1judSKYbk8LcNXgOv5206APXV1NB9+HjIqhAlSVTd6Qq6F3EgSVooOJP8ZX0CEjKGYVVraPAAAAAASUVORK5CYII=\n"
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABvElEQVR4nJ3S32/TMBAH8DvHTtylTdYfrN3YBg8gtpdJCGn/PY/AX8C6SQghuiqjbVB/JHFqxz5elrSqEA/c2+mj79myD+B/Cw96xpmt6LnhB+ZLKC3Q39ATcacE6xztxiIAEgL3u8NR25WZ8R9+mTrpETHi/Pj1+aXHrPaqdOzqsUxWlcCo//7DKMydBlQfiwaBIQCTr96NgkWCIgopN1QjckPIh7fX4edPSfc2lGlqmtsiIvCwNxI/vtwZtwaTbWgPgbV7Mhk/fKfexZmfJhr3kHntWM4mc9G7ePOCfi/N7hGYIDMcbCdF+2Z4ebJZfpsiQ3pGp4nH0XYbHl9d9dV8Nk31Luk0QyuiWHR89XO2KCRH2EtyjqQKt/WxXKoKLCHukoAbu9pAN4+FCgPhBT5oC8AAAIg8VqpNURYWyKyeVgoEa75MtFpWhp2zt6fVbJY85sY2ZwIEUb/y48HL01a2XaeFdm6HGA9aeHJ03lk83ifzZWEtQYOks/kRhGp6l85Vqaxze2vCXJaLYTi5/+oCDMBWdn+Hsrzsy3L8tGZRUJnamtXkfjdfE6GUVGg4QPSk1gAgOCvr4L/rD8eo3Qv2ogogAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    ind = random.randint(0, len(X_test_1)-1)\n",
        "    print(ind)\n",
        "    image_predicted_1 = X_test_1[ind].copy()\n",
        "    image_predicted_1 = image_predicted_1.reshape((28, 28))\n",
        "    image_predicted_1 = image_predicted_1 * 255\n",
        "    image_predicted_1 = image_predicted_1.astype('uint8')\n",
        "    dp.display_png(Image.fromarray(image_predicted_1))\n",
        "    image_predicted_2 = X_test_2[ind].copy()\n",
        "    image_predicted_2 = image_predicted_2.reshape((28, 28))\n",
        "    image_predicted_2 = image_predicted_2 * 255\n",
        "    image_predicted_2 = image_predicted_2.astype('uint8')\n",
        "    dp.display_png(Image.fromarray(image_predicted_2))\n",
        "    p,q = model_complete.predict([X_test_1[ind].reshape(1, 28, 28, 1), X_test_2[ind].reshape(1, 28, 28, 1)] )\n",
        "    image_resulted = q\n",
        "    image_resulted = image_resulted.reshape((28, 28))\n",
        "    image_resulted = image_resulted * 255\n",
        "    image_resulted = image_resulted.astype('uint8')\n",
        "    dp.display_png(Image.fromarray(image_resulted))\n",
        "\n",
        "    #print(\"Prediction for %s: %s\" % (y_test[ind], p))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "New_MNIST.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}